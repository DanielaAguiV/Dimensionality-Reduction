{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from categorical_scatter import categorical_scatter_2d\n",
    "\n",
    "class TSNE():\n",
    "\n",
    "    def neg_squared_euc_dists(X):\n",
    "        \"\"\"Compute matrix containing negative squared euclidean\n",
    "        distance for all pairs of points in input matrix X\n",
    "        # Arguments:\n",
    "            X: matrix of size NxD\n",
    "        # Returns:\n",
    "            NxN matrix D, with entry D_ij = negative squared\n",
    "            euclidean distance between rows X_i and X_j\n",
    "        \"\"\"\n",
    "        # Math? See https://stackoverflow.com/questions/37009647\n",
    "        sum_X = np.sum(np.square(X), 1)\n",
    "        D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "        return -D\n",
    "\n",
    "\n",
    "    def softmax(X, diag_zero=True, zero_index=None):\n",
    "        \"\"\"Compute softmax values for each row of matrix X.\"\"\"\n",
    "\n",
    "        # Subtract max for numerical stability\n",
    "        e_x = np.exp(X - np.max(X, axis=1).reshape([-1, 1]))\n",
    "\n",
    "        # We usually want diagonal probailities to be 0.\n",
    "        if zero_index is None:\n",
    "            if diag_zero:\n",
    "                np.fill_diagonal(e_x, 0.)\n",
    "        else:\n",
    "            e_x[:, zero_index] = 0.\n",
    "\n",
    "        # Add a tiny constant for stability of log we take later\n",
    "        e_x = e_x + 1e-8  # numerical stability\n",
    "\n",
    "        return e_x / e_x.sum(axis=1).reshape([-1, 1])\n",
    "\n",
    "\n",
    "    def calc_prob_matrix(distances, sigmas=None, zero_index=None):\n",
    "        \"\"\"Convert a distances matrix to a matrix of probabilities.\"\"\"\n",
    "        if sigmas is not None:\n",
    "            two_sig_sq = 2. * np.square(sigmas.reshape((-1, 1)))\n",
    "            return softmax(distances / two_sig_sq, zero_index=zero_index)\n",
    "        else:\n",
    "            return softmax(distances, zero_index=zero_index)\n",
    "\n",
    "\n",
    "    def binary_search(eval_fn, target, tol=1e-10, max_iter=10000,\n",
    "                    lower=1e-20, upper=1000.):\n",
    "        \"\"\"Perform a binary search over input values to eval_fn.\n",
    "        # Arguments\n",
    "            eval_fn: Function that we are optimising over.\n",
    "            target: Target value we want the function to output.\n",
    "            tol: Float, once our guess is this close to target, stop.\n",
    "            max_iter: Integer, maximum num. iterations to search for.\n",
    "            lower: Float, lower bound of search range.\n",
    "            upper: Float, upper bound of search range.\n",
    "        # Returns:\n",
    "            Float, best input value to function found during search.\n",
    "        \"\"\"\n",
    "        for i in range(max_iter):\n",
    "            guess = (lower + upper) / 2.\n",
    "            val = eval_fn(guess)\n",
    "            if val > target:\n",
    "                upper = guess\n",
    "            else:\n",
    "                lower = guess\n",
    "            if np.abs(val - target) <= tol:\n",
    "                break\n",
    "        return guess\n",
    "\n",
    "\n",
    "    def calc_perplexity(prob_matrix):\n",
    "        \"\"\"Calculate the perplexity of each row\n",
    "        of a matrix of probabilities.\"\"\"\n",
    "        entropy = -np.sum(prob_matrix * np.log2(prob_matrix), 1)\n",
    "        perplexity = 2 ** entropy\n",
    "        return perplexity\n",
    "\n",
    "\n",
    "    def perplexity(distances, sigmas, zero_index):\n",
    "        \"\"\"Wrapper function for quick calculation of\n",
    "        perplexity over a distance matrix.\"\"\"\n",
    "        return calc_perplexity(\n",
    "            calc_prob_matrix(distances, sigmas, zero_index))\n",
    "\n",
    "\n",
    "    def find_optimal_sigmas(distances, target_perplexity):\n",
    "        \"\"\"For each row of distances matrix, find sigma that results\n",
    "        in target perplexity for that role.\"\"\"\n",
    "        sigmas = []\n",
    "        # For each row of the matrix (each point in our dataset)\n",
    "        for i in range(distances.shape[0]):\n",
    "            # Make fn that returns perplexity of this row given sigma\n",
    "            eval_fn = lambda sigma: \\\n",
    "                perplexity(distances[i:i+1, :], np.array(sigma), i)\n",
    "            # Binary search over sigmas to achieve target perplexity\n",
    "            correct_sigma = binary_search(eval_fn, target_perplexity)\n",
    "            # Append the resulting sigma to our output array\n",
    "            sigmas.append(correct_sigma)\n",
    "        return np.array(sigmas)\n",
    "\n",
    "\n",
    "\n",
    "    def q_tsne(Y):\n",
    "        \"\"\"t-SNE: Given low-dimensional representations Y, compute\n",
    "        matrix of joint probabilities with entries q_ij.\"\"\"\n",
    "        distances = neg_squared_euc_dists(Y)\n",
    "        inv_distances = np.power(1. - distances, -1)\n",
    "        np.fill_diagonal(inv_distances, 0.)\n",
    "        return inv_distances / np.sum(inv_distances), inv_distances\n",
    "\n",
    "\n",
    "    def tsne_grad(P, Q, Y, distances):\n",
    "        \"\"\"t-SNE: Estimate the gradient of the cost with respect to Y.\"\"\"\n",
    "        pq_diff = P - Q  # NxN matrix\n",
    "        pq_expanded = np.expand_dims(pq_diff, 2)  # NxNx1\n",
    "        y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)  # NxNx2\n",
    "        # Expand our distances matrix so can multiply by y_diffs\n",
    "        distances_expanded = np.expand_dims(distances, 2)  # NxNx1\n",
    "        # Weight this (NxNx2) by distances matrix (NxNx1)\n",
    "        y_diffs_wt = y_diffs * distances_expanded  # NxNx2\n",
    "        grad = 4. * (pq_expanded * y_diffs_wt).sum(1)  # Nx2\n",
    "        return grad\n",
    "\n",
    "\n",
    "    def p_joint(X, target_perplexity):\n",
    "        \"\"\"Given a data matrix X, gives joint probabilities matrix.\n",
    "        # Arguments\n",
    "            X: Input data matrix.\n",
    "        # Returns:\n",
    "            P: Matrix with entries p_ij = joint probabilities.\n",
    "        \"\"\"\n",
    "        # Get the negative euclidian distances matrix for our data\n",
    "        distances = neg_squared_euc_dists(X)\n",
    "        # Find optimal sigma for each row of this distances matrix\n",
    "        sigmas = find_optimal_sigmas(distances, target_perplexity)\n",
    "        # Calculate the probabilities based on these optimal sigmas\n",
    "        p_conditional = calc_prob_matrix(distances, sigmas)\n",
    "        # Go from conditional to joint probabilities matrix\n",
    "        P = p_conditional_to_joint(p_conditional)\n",
    "        return P\n",
    "\n",
    "\n",
    "    def estimate_sne(X, y, P, rng, num_iters, q_fn, grad_fn, learning_rate,\n",
    "                    momentum, plot):\n",
    "        \"\"\"Estimates a SNE model.\n",
    "        # Arguments\n",
    "            X: Input data matrix.\n",
    "            y: Class labels for that matrix.\n",
    "            P: Matrix of joint probabilities.\n",
    "            rng: np.random.RandomState().\n",
    "            num_iters: Iterations to train for.\n",
    "            q_fn: Function that takes Y and gives Q prob matrix.\n",
    "            plot: How many times to plot during training.\n",
    "        # Returns:\n",
    "            Y: Matrix, low-dimensional representation of X.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise our 2D representation\n",
    "        Y = rng.normal(0., 0.0001, [X.shape[0], 2])\n",
    "\n",
    "        # Initialise past values (used for momentum)\n",
    "        if momentum:\n",
    "            Y_m2 = Y.copy()\n",
    "            Y_m1 = Y.copy()\n",
    "\n",
    "        # Start gradient descent loop\n",
    "        for i in range(num_iters):\n",
    "\n",
    "            # Get Q and distances (distances only used for t-SNE)\n",
    "            Q, distances = q_fn(Y)\n",
    "            # Estimate gradients with respect to Y\n",
    "            grads = grad_fn(P, Q, Y, distances)\n",
    "\n",
    "            # Update Y\n",
    "            Y = Y - learning_rate * grads\n",
    "            if momentum:  # Add momentum\n",
    "                Y += momentum * (Y_m1 - Y_m2)\n",
    "                # Update previous Y's for momentum\n",
    "                Y_m2 = Y_m1.copy()\n",
    "                Y_m1 = Y.copy()\n",
    "\n",
    "            # Plot sometimes\n",
    "            if plot and i % (num_iters / plot) == 0:\n",
    "                categorical_scatter_2d(Y, y, alpha=1.0, ms=6,\n",
    "                                    show=True, figsize=(9, 6))\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.SVD_np import SVD\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = array([\n",
    " [1,2,3,4,5,6,7,8,9,10],\n",
    " [11,12,13,14,15,16,17,18,19,20],\n",
    " [21,22,23,24,25,26,27,28,29,30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_svd = SVD(n_components = 2)\n",
    "my_svd.fit(A)\n",
    "y = my_svd.transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18.52157747,   6.47697214],\n",
       "       [-49.81310011,   1.91182038],\n",
       "       [-81.10462276,  -2.65333138]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised.svd import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_svd = SVD(n_components = 1)\n",
    "my_svd.fit(input_matrix)\n",
    "my_svd.transform(input_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
